# ControlNet Inpainting - å›¾åƒè¡¥å…¨æ¨¡å‹

åŸºäº [lllyasviel/ControlNet](https://github.com/lllyasviel/ControlNet) å®ç°çš„å›¾åƒè¡¥å…¨ï¼ˆInpaintingï¼‰æ¨¡å‹ã€‚

æœ¬é¡¹ç›®ä½¿ç”¨ **Stable Diffusion v1.5** ä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œè®­ç»ƒ ControlNet æ¥å­¦ä¹ æ ¹æ®é®æŒ¡å›¾åƒå’Œ mask è¿›è¡Œå›¾åƒè¡¥å…¨ã€‚

## ğŸ“‹ ç›®å½•

- [ç‰¹æ€§](#ç‰¹æ€§)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
- [è®­ç»ƒ](#è®­ç»ƒ)
- [æ¨ç†](#æ¨ç†)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [æŠ€æœ¯ç»†èŠ‚](#æŠ€æœ¯ç»†èŠ‚)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

## âœ¨ ç‰¹æ€§

- âœ… åŸºäº lllyasviel/ControlNet åŸå§‹å®ç°
- âœ… ä½¿ç”¨ Stable Diffusion v1.5 é¢„è®­ç»ƒæƒé‡
- âœ… è‡ªåŠ¨ä» COCO æ•°æ®é›†ç”Ÿæˆè®­ç»ƒæ•°æ®
- âœ… æ”¯æŒçŸ©å½¢å’Œä¸è§„åˆ™ mask
- âœ… æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16/BF16ï¼‰
- âœ… æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒï¼ˆvia Accelerate æˆ– PyTorch Lightningï¼‰
- âœ… æä¾› DDPM å’Œ DDIM é‡‡æ ·å™¨
- âœ… å®Œæ•´çš„è®­ç»ƒå’Œæ¨ç†æµç¨‹
- âœ… TensorBoard æ—¥å¿—è®°å½•
- âœ… **æ–°å¢ï¼šPyTorch Lightning ç‰ˆæœ¬ï¼ˆæ›´ç®€æ´ã€æ›´å¼ºå¤§ï¼‰**

## ğŸ”§ ç¯å¢ƒé…ç½®

### 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# ä½¿ç”¨ conda
conda create -n controlnet_inpainting python=3.9
conda activate controlnet_inpainting

# æˆ–ä½¿ç”¨ venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows
```

### 2. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### ä¸»è¦ä¾èµ–

- PyTorch >= 2.0
- Diffusers >= 0.21.0
- Transformers >= 4.30.0
- Accelerate >= 0.20.0
- CUDA 11.8+ (GPU è®­ç»ƒ)

## ğŸ“¦ æ•°æ®å‡†å¤‡

### æ–¹å¼ 1ï¼šä½¿ç”¨ COCO æ•°æ®é›†ï¼ˆæ¨èï¼‰

1. **ä¸‹è½½ COCO æ•°æ®é›†**

```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/coco

# ä¸‹è½½ train2017 å›¾åƒé›†ï¼ˆ~18GBï¼‰
cd data/coco
wget http://images.cocodataset.org/zips/train2017.zip
unzip train2017.zip

# ä¸‹è½½æ ‡æ³¨æ–‡ä»¶ï¼ˆ~241MBï¼‰
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
unzip annotations_trainval2017.zip
```

2. **æ•°æ®é›†ç»“æ„**

```
data/coco/
â”œâ”€â”€ train2017/           # è®­ç»ƒå›¾åƒ
â”‚   â”œâ”€â”€ 000000000009.jpg
â”‚   â”œâ”€â”€ 000000000025.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ annotations/
    â””â”€â”€ instances_train2017.json
```

### æ–¹å¼ 2ï¼šä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†

ä¿®æ”¹ `data.py` ä¸­çš„ `CocoInpaintingDataset` ç±»æ¥é€‚é…ä½ çš„æ•°æ®æ ¼å¼ã€‚

### æµ‹è¯•æ•°æ®åŠ è½½å™¨

```bash
# ä¿®æ”¹ data.py æœ«å°¾çš„è·¯å¾„
python data.py
```

è¿™å°†ç”Ÿæˆä¸€ä¸ªæ ·æœ¬å¯è§†åŒ–å›¾åƒ `data_sample.png`ã€‚

## ğŸš€ è®­ç»ƒ

æœ¬é¡¹ç›®æä¾›ä¸¤ä¸ªè®­ç»ƒç‰ˆæœ¬ï¼Œè®­ç»ƒé€»è¾‘å®Œå…¨ç›¸åŒï¼š

### ç‰ˆæœ¬ 1ï¼šPyTorch Lightningï¼ˆæ¨è âš¡ï¼‰

**æ›´ç®€æ´ã€æ›´å¼ºå¤§ã€è‡ªåŠ¨åŒ–ç¨‹åº¦æ›´é«˜**

```bash
python train_lightning.py \
  --image_dir data/coco/train2017 \
  --ann_file data/coco/annotations/instances_train2017.json \
  --batch_size 4 \
  --num_epochs 100 \
  --learning_rate 1e-5 \
  --precision 16-mixed \
  --devices 1
```

**ä¼˜åŠ¿ï¼š**
- âœ¨ ä»£ç æ›´ç®€æ´ï¼ˆ150 è¡Œ vs 420 è¡Œï¼‰
- âœ¨ è‡ªåŠ¨åˆ†å¸ƒå¼è®­ç»ƒ
- âœ¨ è‡ªåŠ¨ checkpoint ç®¡ç†
- âœ¨ æ›´å¥½çš„æ—¥å¿—å’Œå¯è§†åŒ–

è¯¦è§ [LIGHTNING_GUIDE.md](LIGHTNING_GUIDE.md)

### ç‰ˆæœ¬ 2ï¼šåŸå§‹è®­ç»ƒè„šæœ¬

**å®Œæ•´æ§åˆ¶è®­ç»ƒæµç¨‹ï¼Œé€‚åˆå­¦ä¹ **

```bash
python train.py \
  --image_dir data/coco/train2017 \
  --ann_file data/coco/annotations/instances_train2017.json \
  --pretrained_model_name_or_path runwayml/stable-diffusion-v1-5 \
  --batch_size 4 \
  --num_epochs 100 \
  --learning_rate 1e-5 \
  --output_dir ./outputs \
  --mixed_precision fp16 \
  --save_steps 1000 \
  --log_steps 50
```

### è®­ç»ƒå‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|-----|------|--------|
| `--image_dir` | COCO å›¾åƒç›®å½• | å¿…å¡« |
| `--ann_file` | COCO æ ‡æ³¨æ–‡ä»¶ | å¿…å¡« |
| `--pretrained_model_name_or_path` | Stable Diffusion æ¨¡å‹è·¯å¾„ | `runwayml/stable-diffusion-v1-5` |
| `--batch_size` | æ‰¹æ¬¡å¤§å° | 4 |
| `--num_epochs` | è®­ç»ƒè½®æ•° | 100 |
| `--learning_rate` | å­¦ä¹ ç‡ | 1e-5 |
| `--output_dir` | è¾“å‡ºç›®å½• | `./outputs` |
| `--mixed_precision` | æ··åˆç²¾åº¦ï¼ˆno/fp16/bf16ï¼‰ | fp16 |
| `--save_steps` | ä¿å­˜é—´éš”æ­¥æ•° | 1000 |
| `--num_workers` | æ•°æ®åŠ è½½çº¿ç¨‹æ•° | 4 |

### å¤šGPUè®­ç»ƒ

```bash
# ä½¿ç”¨ accelerate é…ç½®å¤š GPU
accelerate config

# å¯åŠ¨è®­ç»ƒ
accelerate launch train.py \
  --image_dir data/coco/train2017 \
  --ann_file data/coco/annotations/instances_train2017.json \
  --batch_size 8 \
  --num_epochs 100
```

### ç›‘æ§è®­ç»ƒ

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir outputs/controlnet_inpainting_*/logs

# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
# http://localhost:6006
```

### è®­ç»ƒè¾“å‡º

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
outputs/controlnet_inpainting_20241110_120000/
â”œâ”€â”€ logs/                          # TensorBoard æ—¥å¿—
â”œâ”€â”€ checkpoint-1000/               # ä¸­é—´ checkpoint
â”‚   â”œâ”€â”€ controlnet.pth            # ControlNet æƒé‡
â”‚   â”œâ”€â”€ optimizer.pth             # ä¼˜åŒ–å™¨çŠ¶æ€
â”‚   â””â”€â”€ training_state.pth        # è®­ç»ƒçŠ¶æ€
â””â”€â”€ final_model/                   # æœ€ç»ˆæ¨¡å‹
    â””â”€â”€ controlnet.pth
```

## ğŸ¨ æ¨ç†

### åŸºç¡€æ¨ç†å‘½ä»¤

```bash
python infer.py \
  --checkpoint_path outputs/controlnet_inpainting_*/final_model/controlnet.pth \
  --input_image test_images/sample.jpg \
  --input_mask test_images/mask.png \
  --output_dir ./outputs/inference \
  --num_inference_steps 50 \
  --scheduler ddpm
```

### æ¨ç†å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|-----|------|--------|
| `--checkpoint_path` | ControlNet æƒé‡è·¯å¾„ | å¿…å¡« |
| `--input_image` | è¾“å…¥å›¾åƒè·¯å¾„ | å¿…å¡« |
| `--input_mask` | Mask å›¾åƒè·¯å¾„ï¼ˆç™½è‰²=è¡¥å…¨åŒºåŸŸï¼‰ | å¿…å¡« |
| `--output_dir` | è¾“å‡ºç›®å½• | `./outputs/inference` |
| `--num_inference_steps` | æ¨ç†æ­¥æ•° | 50 |
| `--scheduler` | é‡‡æ ·å™¨ï¼ˆddpm/ddimï¼‰ | ddpm |
| `--seed` | éšæœºç§å­ | 42 |

### å‡†å¤‡æ¨ç†è¾“å…¥

1. **è¾“å…¥å›¾åƒ**ï¼šä»»æ„ RGB å›¾åƒ
2. **Mask å›¾åƒ**ï¼šç°åº¦å›¾åƒï¼Œç™½è‰²åŒºåŸŸè¡¨ç¤ºéœ€è¦è¡¥å…¨çš„éƒ¨åˆ†

```python
# ç¤ºä¾‹ï¼šåˆ›å»ºç®€å•çš„çŸ©å½¢ mask
from PIL import Image, ImageDraw

mask = Image.new('L', (512, 512), 0)
draw = ImageDraw.Draw(mask)
draw.rectangle([100, 100, 400, 400], fill=255)
mask.save('mask.png')
```

### æ¨ç†è¾“å‡º

```
outputs/inference/
â”œâ”€â”€ inpainted.png      # è¡¥å…¨åçš„å›¾åƒ
â””â”€â”€ comparison.png     # å¯¹æ¯”å›¾ï¼ˆè¾“å…¥/mask/è¾“å‡ºï¼‰
```

### å¿«é€Ÿæ¨ç†ï¼ˆDDIMï¼‰

```bash
# ä½¿ç”¨ DDIM é‡‡æ ·å™¨ï¼Œæ›´å¿«é€Ÿï¼ˆ20 æ­¥ï¼‰
python infer.py \
  --checkpoint_path outputs/.../final_model/controlnet.pth \
  --input_image test.jpg \
  --input_mask mask.png \
  --scheduler ddim \
  --num_inference_steps 20
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
inpainting_image/
â”œâ”€â”€ æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ data.py                  # æ•°æ®é›†åŠ è½½å™¨
â”‚   â”œâ”€â”€ model.py                 # ControlNet æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ train.py                 # è®­ç»ƒè„šæœ¬ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰
â”‚   â”œâ”€â”€ train_lightning.py       # è®­ç»ƒè„šæœ¬ï¼ˆLightning ç‰ˆæœ¬ï¼‰âš¡
â”‚   â”œâ”€â”€ lightning_module.py      # Lightning æ¨¡å—å°è£…
â”‚   â”œâ”€â”€ lightning_data.py        # Lightning DataModule
â”‚   â””â”€â”€ infer.py                 # æ¨ç†è„šæœ¬
â”‚
â”œâ”€â”€ æ–‡æ¡£
â”‚   â”œâ”€â”€ README.md                # ä¸»æ–‡æ¡£
â”‚   â”œâ”€â”€ LIGHTNING_GUIDE.md       # Lightning ä½¿ç”¨æŒ‡å—
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md     # é¡¹ç›®ç»“æ„è¯´æ˜
â”‚   â””â”€â”€ USAGE_EXAMPLES.md        # ä½¿ç”¨ç¤ºä¾‹
â”‚
â”œâ”€â”€ å·¥å…·
â”‚   â”œâ”€â”€ create_test_mask.py      # åˆ›å»ºæµ‹è¯• mask
â”‚   â”œâ”€â”€ test_installation.py     # æµ‹è¯•ç¯å¢ƒ
â”‚   â””â”€â”€ quick_start.sh           # å¿«é€Ÿå¯åŠ¨
â”‚
â””â”€â”€ é…ç½®
    â”œâ”€â”€ requirements.txt         # ä¾èµ–åº“
    â”œâ”€â”€ config_example.yaml      # é…ç½®ç¤ºä¾‹
    â””â”€â”€ .gitignore              # Git å¿½ç•¥è§„åˆ™
```

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### æ¨¡å‹æ¶æ„

```
è¾“å…¥: masked_image [B,3,512,512] + mask [B,1,512,512]
  â†“
VAE Encoder (å†»ç»“)
  â†“
latent [B,4,64,64]
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ControlNet åˆ†æ”¯            â”‚
â”‚   â”œâ”€â”€ Conditioning Embedding â”‚
â”‚   â”œâ”€â”€ Down Blocks           â”‚
â”‚   â””â”€â”€ Zero Convolutions     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“ (ç‰¹å¾æ³¨å…¥)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UNet ä¸»å¹² (å†»ç»“)           â”‚
â”‚   â”œâ”€â”€ Down Blocks           â”‚
â”‚   â”œâ”€â”€ Mid Block             â”‚
â”‚   â””â”€â”€ Up Blocks             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
é¢„æµ‹å™ªå£° [B,4,64,64]
  â†“
VAE Decoder (å†»ç»“)
  â†“
è¾“å‡º: inpainted_image [B,3,512,512]
```

### è®­ç»ƒç­–ç•¥

1. **å†»ç»“ UNet**ï¼šåªè®­ç»ƒ ControlNet åˆ†æ”¯ï¼Œä¿æŒé¢„è®­ç»ƒæƒé‡
2. **Zero Convolution**ï¼šç‰¹å¾æ³¨å…¥å±‚åˆå§‹åŒ–ä¸ºé›¶ï¼Œè®­ç»ƒåˆæœŸä¸å½±å“ä¸»å¹²
3. **Latent Space**ï¼šåœ¨ 64Ã—64 latent space ä¸­è®­ç»ƒï¼ˆä¸æ˜¯ 512Ã—512ï¼‰
4. **å™ªå£°é¢„æµ‹**ï¼šé¢„æµ‹åŠ å…¥çš„å™ªå£°ï¼Œè€Œéç›´æ¥é¢„æµ‹å›¾åƒ

### å…³é”®è¶…å‚æ•°

- **å­¦ä¹ ç‡**ï¼š1e-5ï¼ˆAdamWï¼‰
- **è®­ç»ƒæ­¥æ•°**ï¼šå»ºè®® 50K-100K æ­¥
- **æ‰¹æ¬¡å¤§å°**ï¼š4-8ï¼ˆå–å†³äº GPU æ˜¾å­˜ï¼‰
- **å›¾åƒå°ºå¯¸**ï¼š512Ã—512ï¼ˆStable Diffusion æ ‡å‡†ï¼‰
- **Mask æ¯”ä¾‹**ï¼š10%-30% å›¾åƒé¢ç§¯

## â“ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒéœ€è¦å¤šå°‘æ˜¾å­˜ï¼Ÿ

- **æœ€å°é…ç½®**ï¼š12GBï¼ˆbatch_size=1, fp16ï¼‰
- **æ¨èé…ç½®**ï¼š24GBï¼ˆbatch_size=4, fp16ï¼‰
- **é«˜é…ç½®**ï¼š40GB+ï¼ˆbatch_size=8+ï¼‰

### Q2: è®­ç»ƒéœ€è¦å¤šä¹…ï¼Ÿ

- **å•å¡ RTX 3090**ï¼šçº¦ 3-5 å¤©ï¼ˆ100 epochs, 118K å›¾åƒï¼‰
- **å¤šå¡ A100**ï¼šçº¦ 1-2 å¤©

### Q3: é¦–æ¬¡è¿è¡Œå¾ˆæ…¢ï¼Ÿ

é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆ~5GBï¼‰ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚å¯ä»¥è®¾ç½® HuggingFace ç¼“å­˜è·¯å¾„ï¼š

```bash
export HF_HOME=/path/to/cache
```

### Q4: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

```bash
# å‡å°æ‰¹æ¬¡å¤§å°
--batch_size 1

# ä½¿ç”¨æ··åˆç²¾åº¦
--mixed_precision fp16

# å‡å°‘æ•°æ®åŠ è½½çº¿ç¨‹
--num_workers 0
```

### Q5: å¦‚ä½•åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒï¼Ÿ

ä¿®æ”¹ `data.py` ä¸­çš„ `CocoInpaintingDataset` ç±»ï¼š

```python
class CustomInpaintingDataset(Dataset):
    def __init__(self, image_paths, mask_paths):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
    
    def __getitem__(self, idx):
        # åŠ è½½ä½ çš„æ•°æ®
        image = load_image(self.image_paths[idx])
        mask = load_mask(self.mask_paths[idx])
        # è¿”å› original_image, masked_image, mask
        ...
```

### Q6: æ¨ç†ç»“æœä¸ç†æƒ³ï¼Ÿ

- å¢åŠ æ¨ç†æ­¥æ•°ï¼ˆ`--num_inference_steps 100`ï¼‰
- å°è¯•ä¸åŒçš„éšæœºç§å­
- ç¡®ä¿æ¨¡å‹è®­ç»ƒå……åˆ†ï¼ˆè‡³å°‘ 50K æ­¥ï¼‰
- æ£€æŸ¥ mask æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆç™½è‰²=è¡¥å…¨åŒºåŸŸï¼‰

### Q7: æ”¯æŒæ›´é«˜åˆ†è¾¨ç‡å—ï¼Ÿ

å½“å‰å®ç°é’ˆå¯¹ 512Ã—512 ä¼˜åŒ–ã€‚å¦‚éœ€æ›´é«˜åˆ†è¾¨ç‡ï¼š

1. ä½¿ç”¨ Stable Diffusion 2.xï¼ˆæ”¯æŒ 768Ã—768ï¼‰
2. ä¿®æ”¹ `--image_size` å‚æ•°
3. éœ€è¦æ›´å¤šæ˜¾å­˜

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚

## ğŸ™ è‡´è°¢

- [lllyasviel/ControlNet](https://github.com/lllyasviel/ControlNet) - åŸå§‹ ControlNet å®ç°
- [Stability AI](https://stability.ai/) - Stable Diffusion æ¨¡å‹
- [Hugging Face](https://huggingface.co/) - Diffusers åº“

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿æ Issue æˆ– Pull Requestã€‚

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸ‰**

